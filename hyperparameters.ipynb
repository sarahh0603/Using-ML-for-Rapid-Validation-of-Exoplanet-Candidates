{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4710515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47208944",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('input_data/KOI_cumulative_2025.07.31_21.17.09.csv', comment='#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d7357f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_disposition\n",
       "FALSE POSITIVE    4839\n",
       "CONFIRMED         2746\n",
       "CANDIDATE         1979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['koi_disposition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ace72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e213c5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[data['koi_disposition'] == 'CANDIDATE']['koi_score'] > 0.95).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac9dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ExoplanetCandidate'] = data['koi_disposition'].apply(lambda x: 1 if x == 'CANDIDATE' or x == 'CONFIRMED' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef6d519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output_data/scaler_ksmet.sav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "short_cols = ['koi_period', 'koi_duration', 'koi_depth', 'koi_prad',\n",
    "              'koi_teq', 'koi_insol', 'koi_steff', 'koi_slogg', 'koi_srad', 'koi_smet', 'ExoplanetCandidate']\n",
    "\n",
    "data = data[short_cols].dropna()\n",
    "data.to_csv('output_data/KOI_2025.07.31_cleaned.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "X = data.drop(columns=['ExoplanetCandidate'])\n",
    "y = data['ExoplanetCandidate']\n",
    "\n",
    "# Split and scale data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, test_size=0.2, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "joblib.dump(scaler, 'output_data/scaler_ksmet.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44cf9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814975db",
   "metadata": {},
   "source": [
    "# 1. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3074ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 10),  # Regularization strength\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],\n",
    "    'l1_ratio': np.linspace(0, 1, 5)  # Only used when penalty='elasticnet'\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,             # use all CPU cores\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ff92f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n",
      "Best parameters: {'C': 21.54434690031882, 'l1_ratio': 0.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best mean CV accuracy: 0.787249570135201\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'C': 0.0001, 'l1_ratio': 0.0, 'penalty': 'l1'...         0.497004   \n",
      "1    {'C': 0.0001, 'l1_ratio': 0.0, 'penalty': 'l1'...         0.501634   \n",
      "2    {'C': 0.0001, 'l1_ratio': 0.0, 'penalty': 'l1'...              NaN   \n",
      "3    {'C': 0.0001, 'l1_ratio': 0.0, 'penalty': 'l2'...         0.734131   \n",
      "4    {'C': 0.0001, 'l1_ratio': 0.0, 'penalty': 'l2'...         0.728137   \n",
      "..                                                 ...              ...   \n",
      "595  {'C': 10000.0, 'l1_ratio': 1.0, 'penalty': 'el...         0.783435   \n",
      "596  {'C': 10000.0, 'l1_ratio': 1.0, 'penalty': 'el...              NaN   \n",
      "597  {'C': 10000.0, 'l1_ratio': 1.0, 'penalty': 'no...              NaN   \n",
      "598  {'C': 10000.0, 'l1_ratio': 1.0, 'penalty': 'no...              NaN   \n",
      "599  {'C': 10000.0, 'l1_ratio': 1.0, 'penalty': 'no...              NaN   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.000255  \n",
      "1          0.002525  \n",
      "2               NaN  \n",
      "3          0.010937  \n",
      "4          0.010676  \n",
      "..              ...  \n",
      "595        0.012875  \n",
      "596             NaN  \n",
      "597             NaN  \n",
      "598             NaN  \n",
      "599             NaN  \n",
      "\n",
      "[600 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models//best_model_lr.sav']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "\n",
    "# Suppress convergence warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Suppress all sklearn UserWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "# Train (fit) the grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Results\n",
    "# -----------------------------\n",
    "\n",
    "# 1. Best parameters\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "\n",
    "# 2. Best mean CV score\n",
    "print(\"Best mean CV accuracy:\", grid.best_score_)\n",
    "\n",
    "# 3. The best estimator (trained on all training data)\n",
    "best_model_lr = grid.best_estimator_\n",
    "\n",
    "# 4. Predictions on test set\n",
    "y_pred_lr = best_model_lr.predict(X_test)\n",
    "\n",
    "# 5. Detailed results for each parameter combination\n",
    "results_df_lr = pd.DataFrame(grid.cv_results_)\n",
    "print(results_df_lr[['params', 'mean_test_score', 'std_test_score']])\n",
    "results_df_lr.to_csv(f'{model_dir}/grid_search_results_lr.csv', index=False)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model_lr, f'{model_dir}/best_model_lr.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ba0fc",
   "metadata": {},
   "source": [
    "# 2. KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e599e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 31, 2)),  # odd numbers 1,3,5,...,29\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    knn,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "528563e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n",
      "Best params: {'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 17, 'p': 1, 'weights': 'distance'}\n",
      "Best score: 0.785069826366154\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...         0.757421   \n",
      "1    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...         0.757421   \n",
      "2    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...         0.750202   \n",
      "3    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...         0.750202   \n",
      "4    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...         0.775672   \n",
      "..                                                 ...              ...   \n",
      "715  {'algorithm': 'brute', 'leaf_size': 40, 'n_nei...         0.777442   \n",
      "716  {'algorithm': 'brute', 'leaf_size': 40, 'n_nei...         0.774720   \n",
      "717  {'algorithm': 'brute', 'leaf_size': 40, 'n_nei...         0.780984   \n",
      "718  {'algorithm': 'brute', 'leaf_size': 40, 'n_nei...         0.773358   \n",
      "719  {'algorithm': 'brute', 'leaf_size': 40, 'n_nei...         0.775672   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.008927  \n",
      "1          0.008927  \n",
      "2          0.007404  \n",
      "3          0.007404  \n",
      "4          0.006848  \n",
      "..              ...  \n",
      "715        0.009044  \n",
      "716        0.006098  \n",
      "717        0.007306  \n",
      "718        0.005316  \n",
      "719        0.008392  \n",
      "\n",
      "[720 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models//best_model_knc.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "\n",
    "best_model_knc = grid.best_estimator_\n",
    "\n",
    "y_pred_knc = best_model_knc.predict(X_test)\n",
    "\n",
    "results_df_knc = pd.DataFrame(grid.cv_results_)\n",
    "print(results_df_knc[['params', 'mean_test_score', 'std_test_score']])\n",
    "results_df_knc.to_csv(f'{model_dir}/grid_search_results_knc.csv', index=False)\n",
    "\n",
    "joblib.dump(best_model_knc, f'{model_dir}/best_model_knc.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056cc1c",
   "metadata": {},
   "source": [
    "# 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94015e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a950069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n",
      "Best params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
      "Best score: 0.8119015512230048\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'criterion': 'gini', 'max_depth': None, 'max_...         0.776079   \n",
      "1    {'criterion': 'gini', 'max_depth': None, 'max_...         0.775673   \n",
      "2    {'criterion': 'gini', 'max_depth': None, 'max_...         0.779759   \n",
      "3    {'criterion': 'gini', 'max_depth': None, 'max_...         0.783164   \n",
      "4    {'criterion': 'gini', 'max_depth': None, 'max_...         0.776626   \n",
      "..                                                 ...              ...   \n",
      "763  {'criterion': 'entropy', 'max_depth': 25, 'max...         0.787521   \n",
      "764  {'criterion': 'entropy', 'max_depth': 25, 'max...         0.795015   \n",
      "765  {'criterion': 'entropy', 'max_depth': 25, 'max...         0.795015   \n",
      "766  {'criterion': 'entropy', 'max_depth': 25, 'max...         0.795015   \n",
      "767  {'criterion': 'entropy', 'max_depth': 25, 'max...         0.795015   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.013279  \n",
      "1          0.012229  \n",
      "2          0.011415  \n",
      "3          0.009857  \n",
      "4          0.008603  \n",
      "..              ...  \n",
      "763        0.010680  \n",
      "764        0.007100  \n",
      "765        0.007100  \n",
      "766        0.007100  \n",
      "767        0.007100  \n",
      "\n",
      "[768 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models//best_model_dtc.sav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "\n",
    "best_model_dtc = grid.best_estimator_\n",
    "\n",
    "y_pred_dtc = best_model_dtc.predict(X_test)\n",
    "\n",
    "results_df_dtc = pd.DataFrame(grid.cv_results_)\n",
    "print(results_df_dtc[['params', 'mean_test_score', 'std_test_score']])\n",
    "results_df_dtc.to_csv(f'{model_dir}/grid_search_results_dtc.csv', index=False)\n",
    "\n",
    "joblib.dump(best_model_dtc, f'{model_dir}/best_model_dtc.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943b23c",
   "metadata": {},
   "source": [
    "# 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63b84318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "Best params: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best CV accuracy: 0.8379158373877577\n",
      "                                                 params  mean_test_score  \\\n",
      "0     {'bootstrap': True, 'criterion': 'gini', 'max_...              NaN   \n",
      "1     {'bootstrap': True, 'criterion': 'gini', 'max_...              NaN   \n",
      "2     {'bootstrap': True, 'criterion': 'gini', 'max_...              NaN   \n",
      "3     {'bootstrap': True, 'criterion': 'gini', 'max_...              NaN   \n",
      "4     {'bootstrap': True, 'criterion': 'gini', 'max_...              NaN   \n",
      "...                                                 ...              ...   \n",
      "1291  {'bootstrap': False, 'criterion': 'entropy', '...         0.836554   \n",
      "1292  {'bootstrap': False, 'criterion': 'entropy', '...         0.836690   \n",
      "1293  {'bootstrap': False, 'criterion': 'entropy', '...         0.833967   \n",
      "1294  {'bootstrap': False, 'criterion': 'entropy', '...         0.836418   \n",
      "1295  {'bootstrap': False, 'criterion': 'entropy', '...         0.837371   \n",
      "\n",
      "      std_test_score  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "...              ...  \n",
      "1291        0.010174  \n",
      "1292        0.010220  \n",
      "1293        0.008303  \n",
      "1294        0.009737  \n",
      "1295        0.010784  \n",
      "\n",
      "[1296 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models//best_model_rf.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV accuracy:\", grid.best_score_)\n",
    "\n",
    "best_model_rf = grid.best_estimator_\n",
    "\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "\n",
    "results_df_rf = pd.DataFrame(grid.cv_results_)\n",
    "print(results_df_rf[['params', 'mean_test_score', 'std_test_score']])\n",
    "results_df_rf.to_csv(f'{model_dir}/grid_search_results_rf.csv', index=False)\n",
    "\n",
    "joblib.dump(best_model_rf, f'{model_dir}/best_model_rf.sav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa384b71",
   "metadata": {},
   "source": [
    "# 5. Transformer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce565301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5679deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Encoder Definition\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.1):\n",
    "    # Normalization and Multi-Head Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Network\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(inputs.shape[-1])(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5904efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Data for Transformer (3D Input)\n",
    "x_train = tf.expand_dims(X_train, axis=-1)  # Shape: (batch_size, num_features, 1)\n",
    "x_test = tf.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Build Model with Transformer Encoder and Dense Layers\n",
    "input_shape = (X_train.shape[1], 1)  # num_features, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b953283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=input_shape)\n",
    "x = transformer_encoder(inputs, head_size=32, num_heads=2, ff_dim=64, dropout=0.1)\n",
    "x = layers.Flatten()(x)  # Flatten Transformer Output\n",
    "x = layers.Dense(32)(x)\n",
    "x = layers.LayerNormalization(axis=-1, center=True, scale=True)(x)\n",
    "x = layers.Dense(16, activation='relu')(x)  # Used to be ReLU\n",
    "x = layers.Dense(8, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af9d5b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 10, 1)       2           ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 10, 1)       449         ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 10, 1)        0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 10, 1)       0           ['dropout[0][0]',                \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10, 64)       128         ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 10, 64)       0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10, 1)        65          ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 10, 1)       0           ['dense_1[0][0]',                \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 10)           0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           352         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 32)          64          ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16)           528         ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 8)            136         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            9           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,735\n",
      "Trainable params: 1,735\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tnn = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "learning_rate = 0.0001  # Default, or try 0.0005 for finer tuning\n",
    "optimizer = tf.keras.optimizers.Adamax(learning_rate=learning_rate)\n",
    "\n",
    "# Compile with the custom optimizer\n",
    "model_tnn.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_tnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db06e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "918/918 [==============================] - 1s 950us/step - loss: 1.2427 - accuracy: 0.5444 - val_loss: 0.9200 - val_accuracy: 0.5904\n",
      "Epoch 2/500\n",
      "918/918 [==============================] - 1s 804us/step - loss: 0.8044 - accuracy: 0.6133 - val_loss: 0.6772 - val_accuracy: 0.6520\n",
      "Epoch 3/500\n",
      "918/918 [==============================] - 1s 778us/step - loss: 0.6604 - accuracy: 0.6566 - val_loss: 0.5925 - val_accuracy: 0.7042\n",
      "Epoch 4/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.5993 - accuracy: 0.6938 - val_loss: 0.5513 - val_accuracy: 0.7304\n",
      "Epoch 5/500\n",
      "918/918 [==============================] - 1s 867us/step - loss: 0.5637 - accuracy: 0.7159 - val_loss: 0.5271 - val_accuracy: 0.7440\n",
      "Epoch 6/500\n",
      "918/918 [==============================] - 1s 861us/step - loss: 0.5398 - accuracy: 0.7287 - val_loss: 0.5101 - val_accuracy: 0.7549\n",
      "Epoch 7/500\n",
      "918/918 [==============================] - 1s 813us/step - loss: 0.5230 - accuracy: 0.7412 - val_loss: 0.4972 - val_accuracy: 0.7658\n",
      "Epoch 8/500\n",
      "918/918 [==============================] - 1s 810us/step - loss: 0.5099 - accuracy: 0.7524 - val_loss: 0.4873 - val_accuracy: 0.7680\n",
      "Epoch 9/500\n",
      "918/918 [==============================] - 1s 830us/step - loss: 0.4996 - accuracy: 0.7562 - val_loss: 0.4795 - val_accuracy: 0.7789\n",
      "Epoch 10/500\n",
      "918/918 [==============================] - 1s 805us/step - loss: 0.4908 - accuracy: 0.7595 - val_loss: 0.4727 - val_accuracy: 0.7810\n",
      "Epoch 11/500\n",
      "918/918 [==============================] - 1s 788us/step - loss: 0.4841 - accuracy: 0.7618 - val_loss: 0.4671 - val_accuracy: 0.7838\n",
      "Epoch 12/500\n",
      "918/918 [==============================] - 1s 892us/step - loss: 0.4782 - accuracy: 0.7675 - val_loss: 0.4631 - val_accuracy: 0.7870\n",
      "Epoch 13/500\n",
      "918/918 [==============================] - 1s 854us/step - loss: 0.4732 - accuracy: 0.7709 - val_loss: 0.4594 - val_accuracy: 0.7854\n",
      "Epoch 14/500\n",
      "918/918 [==============================] - 1s 799us/step - loss: 0.4689 - accuracy: 0.7730 - val_loss: 0.4558 - val_accuracy: 0.7892\n",
      "Epoch 15/500\n",
      "918/918 [==============================] - 1s 859us/step - loss: 0.4649 - accuracy: 0.7762 - val_loss: 0.4528 - val_accuracy: 0.7876\n",
      "Epoch 16/500\n",
      "918/918 [==============================] - 1s 795us/step - loss: 0.4614 - accuracy: 0.7787 - val_loss: 0.4504 - val_accuracy: 0.7859\n",
      "Epoch 17/500\n",
      "918/918 [==============================] - 1s 800us/step - loss: 0.4582 - accuracy: 0.7798 - val_loss: 0.4479 - val_accuracy: 0.7898\n",
      "Epoch 18/500\n",
      "918/918 [==============================] - 1s 794us/step - loss: 0.4556 - accuracy: 0.7813 - val_loss: 0.4458 - val_accuracy: 0.7919\n",
      "Epoch 19/500\n",
      "918/918 [==============================] - 1s 810us/step - loss: 0.4530 - accuracy: 0.7818 - val_loss: 0.4438 - val_accuracy: 0.7941\n",
      "Epoch 20/500\n",
      "918/918 [==============================] - 1s 799us/step - loss: 0.4504 - accuracy: 0.7837 - val_loss: 0.4418 - val_accuracy: 0.7952\n",
      "Epoch 21/500\n",
      "918/918 [==============================] - 1s 804us/step - loss: 0.4479 - accuracy: 0.7847 - val_loss: 0.4402 - val_accuracy: 0.7974\n",
      "Epoch 22/500\n",
      "918/918 [==============================] - 1s 836us/step - loss: 0.4462 - accuracy: 0.7867 - val_loss: 0.4388 - val_accuracy: 0.7947\n",
      "Epoch 23/500\n",
      "918/918 [==============================] - 1s 789us/step - loss: 0.4443 - accuracy: 0.7868 - val_loss: 0.4372 - val_accuracy: 0.7947\n",
      "Epoch 24/500\n",
      "918/918 [==============================] - 1s 803us/step - loss: 0.4424 - accuracy: 0.7916 - val_loss: 0.4365 - val_accuracy: 0.7985\n",
      "Epoch 25/500\n",
      "918/918 [==============================] - 1s 794us/step - loss: 0.4408 - accuracy: 0.7922 - val_loss: 0.4348 - val_accuracy: 0.7947\n",
      "Epoch 26/500\n",
      "918/918 [==============================] - 1s 803us/step - loss: 0.4393 - accuracy: 0.7927 - val_loss: 0.4339 - val_accuracy: 0.7963\n",
      "Epoch 27/500\n",
      "918/918 [==============================] - 1s 794us/step - loss: 0.4378 - accuracy: 0.7923 - val_loss: 0.4325 - val_accuracy: 0.7958\n",
      "Epoch 28/500\n",
      "918/918 [==============================] - 1s 787us/step - loss: 0.4365 - accuracy: 0.7930 - val_loss: 0.4320 - val_accuracy: 0.7979\n",
      "Epoch 29/500\n",
      "918/918 [==============================] - 1s 786us/step - loss: 0.4354 - accuracy: 0.7932 - val_loss: 0.4308 - val_accuracy: 0.7985\n",
      "Epoch 30/500\n",
      "918/918 [==============================] - 1s 815us/step - loss: 0.4341 - accuracy: 0.7941 - val_loss: 0.4299 - val_accuracy: 0.7990\n",
      "Epoch 31/500\n",
      "918/918 [==============================] - 1s 832us/step - loss: 0.4329 - accuracy: 0.7952 - val_loss: 0.4294 - val_accuracy: 0.7996\n",
      "Epoch 32/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.4316 - accuracy: 0.7961 - val_loss: 0.4281 - val_accuracy: 0.8001\n",
      "Epoch 33/500\n",
      "918/918 [==============================] - 1s 814us/step - loss: 0.4308 - accuracy: 0.7972 - val_loss: 0.4273 - val_accuracy: 0.8023\n",
      "Epoch 34/500\n",
      "918/918 [==============================] - 1s 879us/step - loss: 0.4296 - accuracy: 0.7972 - val_loss: 0.4269 - val_accuracy: 0.8023\n",
      "Epoch 35/500\n",
      "918/918 [==============================] - 1s 832us/step - loss: 0.4287 - accuracy: 0.7988 - val_loss: 0.4260 - val_accuracy: 0.8045\n",
      "Epoch 36/500\n",
      "918/918 [==============================] - 1s 831us/step - loss: 0.4278 - accuracy: 0.7976 - val_loss: 0.4258 - val_accuracy: 0.8034\n",
      "Epoch 37/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.4270 - accuracy: 0.8005 - val_loss: 0.4251 - val_accuracy: 0.8034\n",
      "Epoch 38/500\n",
      "918/918 [==============================] - 1s 803us/step - loss: 0.4260 - accuracy: 0.7998 - val_loss: 0.4249 - val_accuracy: 0.8017\n",
      "Epoch 39/500\n",
      "918/918 [==============================] - 1s 844us/step - loss: 0.4253 - accuracy: 0.7996 - val_loss: 0.4236 - val_accuracy: 0.8039\n",
      "Epoch 40/500\n",
      "918/918 [==============================] - 1s 801us/step - loss: 0.4242 - accuracy: 0.8014 - val_loss: 0.4229 - val_accuracy: 0.8066\n",
      "Epoch 41/500\n",
      "918/918 [==============================] - 1s 802us/step - loss: 0.4237 - accuracy: 0.8011 - val_loss: 0.4223 - val_accuracy: 0.8050\n",
      "Epoch 42/500\n",
      "918/918 [==============================] - 1s 791us/step - loss: 0.4229 - accuracy: 0.8028 - val_loss: 0.4218 - val_accuracy: 0.8061\n",
      "Epoch 43/500\n",
      "918/918 [==============================] - 1s 793us/step - loss: 0.4221 - accuracy: 0.8017 - val_loss: 0.4213 - val_accuracy: 0.8066\n",
      "Epoch 44/500\n",
      "918/918 [==============================] - 1s 812us/step - loss: 0.4214 - accuracy: 0.8010 - val_loss: 0.4209 - val_accuracy: 0.8077\n",
      "Epoch 45/500\n",
      "918/918 [==============================] - 1s 830us/step - loss: 0.4208 - accuracy: 0.8020 - val_loss: 0.4206 - val_accuracy: 0.8061\n",
      "Epoch 46/500\n",
      "918/918 [==============================] - 1s 793us/step - loss: 0.4203 - accuracy: 0.8032 - val_loss: 0.4201 - val_accuracy: 0.8088\n",
      "Epoch 47/500\n",
      "918/918 [==============================] - 1s 795us/step - loss: 0.4196 - accuracy: 0.8028 - val_loss: 0.4194 - val_accuracy: 0.8083\n",
      "Epoch 48/500\n",
      "918/918 [==============================] - 1s 800us/step - loss: 0.4192 - accuracy: 0.8029 - val_loss: 0.4197 - val_accuracy: 0.8077\n",
      "Epoch 49/500\n",
      "918/918 [==============================] - 1s 853us/step - loss: 0.4187 - accuracy: 0.8041 - val_loss: 0.4189 - val_accuracy: 0.8088\n",
      "Epoch 50/500\n",
      "918/918 [==============================] - 1s 818us/step - loss: 0.4181 - accuracy: 0.8044 - val_loss: 0.4190 - val_accuracy: 0.8066\n",
      "Epoch 51/500\n",
      "918/918 [==============================] - 1s 805us/step - loss: 0.4176 - accuracy: 0.8031 - val_loss: 0.4184 - val_accuracy: 0.8088\n",
      "Epoch 52/500\n",
      "918/918 [==============================] - 1s 829us/step - loss: 0.4171 - accuracy: 0.8044 - val_loss: 0.4184 - val_accuracy: 0.8077\n",
      "Epoch 53/500\n",
      "918/918 [==============================] - 1s 803us/step - loss: 0.4169 - accuracy: 0.8044 - val_loss: 0.4177 - val_accuracy: 0.8088\n",
      "Epoch 54/500\n",
      "918/918 [==============================] - 1s 791us/step - loss: 0.4164 - accuracy: 0.8041 - val_loss: 0.4177 - val_accuracy: 0.8083\n",
      "Epoch 55/500\n",
      "918/918 [==============================] - 1s 854us/step - loss: 0.4161 - accuracy: 0.8051 - val_loss: 0.4176 - val_accuracy: 0.8072\n",
      "Epoch 56/500\n",
      "918/918 [==============================] - 1s 793us/step - loss: 0.4155 - accuracy: 0.8052 - val_loss: 0.4170 - val_accuracy: 0.8094\n",
      "Epoch 57/500\n",
      "918/918 [==============================] - 1s 792us/step - loss: 0.4155 - accuracy: 0.8045 - val_loss: 0.4163 - val_accuracy: 0.8088\n",
      "Epoch 58/500\n",
      "918/918 [==============================] - 1s 808us/step - loss: 0.4151 - accuracy: 0.8052 - val_loss: 0.4159 - val_accuracy: 0.8110\n",
      "Epoch 59/500\n",
      "918/918 [==============================] - 1s 800us/step - loss: 0.4147 - accuracy: 0.8048 - val_loss: 0.4160 - val_accuracy: 0.8105\n",
      "Epoch 60/500\n",
      "918/918 [==============================] - 1s 794us/step - loss: 0.4144 - accuracy: 0.8058 - val_loss: 0.4161 - val_accuracy: 0.8066\n",
      "Epoch 61/500\n",
      "918/918 [==============================] - 1s 880us/step - loss: 0.4142 - accuracy: 0.8059 - val_loss: 0.4153 - val_accuracy: 0.8088\n",
      "Epoch 62/500\n",
      "918/918 [==============================] - 1s 811us/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.4151 - val_accuracy: 0.8083\n",
      "Epoch 63/500\n",
      "918/918 [==============================] - 1s 842us/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.4147 - val_accuracy: 0.8088\n",
      "Epoch 64/500\n",
      "918/918 [==============================] - 1s 792us/step - loss: 0.4132 - accuracy: 0.8065 - val_loss: 0.4143 - val_accuracy: 0.8115\n",
      "Epoch 65/500\n",
      "918/918 [==============================] - 1s 789us/step - loss: 0.4129 - accuracy: 0.8070 - val_loss: 0.4143 - val_accuracy: 0.8105\n",
      "Epoch 66/500\n",
      "918/918 [==============================] - 1s 805us/step - loss: 0.4126 - accuracy: 0.8055 - val_loss: 0.4141 - val_accuracy: 0.8094\n",
      "Epoch 67/500\n",
      "918/918 [==============================] - 1s 882us/step - loss: 0.4124 - accuracy: 0.8062 - val_loss: 0.4137 - val_accuracy: 0.8088\n",
      "Epoch 68/500\n",
      "918/918 [==============================] - 1s 814us/step - loss: 0.4120 - accuracy: 0.8074 - val_loss: 0.4139 - val_accuracy: 0.8088\n",
      "Epoch 69/500\n",
      "918/918 [==============================] - 1s 802us/step - loss: 0.4117 - accuracy: 0.8075 - val_loss: 0.4131 - val_accuracy: 0.8121\n",
      "Epoch 70/500\n",
      "918/918 [==============================] - 1s 930us/step - loss: 0.4116 - accuracy: 0.8075 - val_loss: 0.4131 - val_accuracy: 0.8110\n",
      "Epoch 71/500\n",
      "918/918 [==============================] - 1s 817us/step - loss: 0.4113 - accuracy: 0.8089 - val_loss: 0.4131 - val_accuracy: 0.8121\n",
      "Epoch 72/500\n",
      "918/918 [==============================] - 1s 913us/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.4133 - val_accuracy: 0.8094\n",
      "Epoch 73/500\n",
      "918/918 [==============================] - 1s 964us/step - loss: 0.4110 - accuracy: 0.8078 - val_loss: 0.4127 - val_accuracy: 0.8110\n",
      "Epoch 74/500\n",
      "918/918 [==============================] - 1s 869us/step - loss: 0.4107 - accuracy: 0.8077 - val_loss: 0.4124 - val_accuracy: 0.8121\n",
      "Epoch 75/500\n",
      "918/918 [==============================] - 1s 817us/step - loss: 0.4104 - accuracy: 0.8088 - val_loss: 0.4125 - val_accuracy: 0.8137\n",
      "Epoch 76/500\n",
      "918/918 [==============================] - 1s 898us/step - loss: 0.4102 - accuracy: 0.8090 - val_loss: 0.4125 - val_accuracy: 0.8126\n",
      "Epoch 77/500\n",
      "918/918 [==============================] - 1s 797us/step - loss: 0.4102 - accuracy: 0.8093 - val_loss: 0.4117 - val_accuracy: 0.8110\n",
      "Epoch 78/500\n",
      "918/918 [==============================] - 1s 788us/step - loss: 0.4098 - accuracy: 0.8092 - val_loss: 0.4117 - val_accuracy: 0.8132\n",
      "Epoch 79/500\n",
      "918/918 [==============================] - 1s 866us/step - loss: 0.4097 - accuracy: 0.8075 - val_loss: 0.4115 - val_accuracy: 0.8137\n",
      "Epoch 80/500\n",
      "918/918 [==============================] - 1s 923us/step - loss: 0.4097 - accuracy: 0.8086 - val_loss: 0.4109 - val_accuracy: 0.8148\n",
      "Epoch 81/500\n",
      "918/918 [==============================] - 1s 897us/step - loss: 0.4094 - accuracy: 0.8081 - val_loss: 0.4110 - val_accuracy: 0.8137\n",
      "Epoch 82/500\n",
      "918/918 [==============================] - 1s 803us/step - loss: 0.4092 - accuracy: 0.8105 - val_loss: 0.4110 - val_accuracy: 0.8143\n",
      "Epoch 83/500\n",
      "918/918 [==============================] - 1s 809us/step - loss: 0.4090 - accuracy: 0.8078 - val_loss: 0.4110 - val_accuracy: 0.8143\n",
      "Epoch 84/500\n",
      "918/918 [==============================] - 1s 782us/step - loss: 0.4089 - accuracy: 0.8081 - val_loss: 0.4110 - val_accuracy: 0.8126\n",
      "Epoch 85/500\n",
      "918/918 [==============================] - 1s 816us/step - loss: 0.4087 - accuracy: 0.8099 - val_loss: 0.4108 - val_accuracy: 0.8137\n",
      "Epoch 86/500\n",
      "918/918 [==============================] - 1s 773us/step - loss: 0.4086 - accuracy: 0.8104 - val_loss: 0.4104 - val_accuracy: 0.8154\n",
      "Epoch 87/500\n",
      "918/918 [==============================] - 1s 795us/step - loss: 0.4085 - accuracy: 0.8095 - val_loss: 0.4106 - val_accuracy: 0.8148\n",
      "Epoch 88/500\n",
      "918/918 [==============================] - 1s 787us/step - loss: 0.4083 - accuracy: 0.8107 - val_loss: 0.4105 - val_accuracy: 0.8164\n",
      "Epoch 89/500\n",
      "918/918 [==============================] - 1s 784us/step - loss: 0.4082 - accuracy: 0.8088 - val_loss: 0.4102 - val_accuracy: 0.8148\n",
      "Epoch 90/500\n",
      "918/918 [==============================] - 1s 805us/step - loss: 0.4080 - accuracy: 0.8097 - val_loss: 0.4105 - val_accuracy: 0.8143\n",
      "Epoch 91/500\n",
      "918/918 [==============================] - 1s 856us/step - loss: 0.4079 - accuracy: 0.8101 - val_loss: 0.4101 - val_accuracy: 0.8143\n",
      "Epoch 92/500\n",
      "918/918 [==============================] - 1s 865us/step - loss: 0.4078 - accuracy: 0.8089 - val_loss: 0.4101 - val_accuracy: 0.8159\n",
      "Epoch 93/500\n",
      "918/918 [==============================] - 1s 898us/step - loss: 0.4077 - accuracy: 0.8101 - val_loss: 0.4104 - val_accuracy: 0.8154\n",
      "Epoch 94/500\n",
      "918/918 [==============================] - 1s 846us/step - loss: 0.4076 - accuracy: 0.8096 - val_loss: 0.4102 - val_accuracy: 0.8159\n",
      "Epoch 95/500\n",
      "918/918 [==============================] - 1s 864us/step - loss: 0.4075 - accuracy: 0.8100 - val_loss: 0.4101 - val_accuracy: 0.8159\n",
      "Epoch 96/500\n",
      "918/918 [==============================] - 1s 807us/step - loss: 0.4074 - accuracy: 0.8111 - val_loss: 0.4096 - val_accuracy: 0.8154\n",
      "Epoch 97/500\n",
      "918/918 [==============================] - 1s 799us/step - loss: 0.4072 - accuracy: 0.8095 - val_loss: 0.4096 - val_accuracy: 0.8148\n",
      "Epoch 98/500\n",
      "918/918 [==============================] - 1s 815us/step - loss: 0.4071 - accuracy: 0.8093 - val_loss: 0.4095 - val_accuracy: 0.8164\n",
      "Epoch 99/500\n",
      "918/918 [==============================] - 1s 858us/step - loss: 0.4069 - accuracy: 0.8100 - val_loss: 0.4095 - val_accuracy: 0.8159\n",
      "Epoch 100/500\n",
      "918/918 [==============================] - 1s 875us/step - loss: 0.4066 - accuracy: 0.8095 - val_loss: 0.4096 - val_accuracy: 0.8164\n",
      "Epoch 101/500\n",
      "918/918 [==============================] - 1s 860us/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.4094 - val_accuracy: 0.8164\n",
      "Epoch 102/500\n",
      "918/918 [==============================] - 1s 827us/step - loss: 0.4066 - accuracy: 0.8101 - val_loss: 0.4089 - val_accuracy: 0.8197\n",
      "Epoch 103/500\n",
      "918/918 [==============================] - 1s 834us/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.4094 - val_accuracy: 0.8175\n",
      "Epoch 104/500\n",
      "918/918 [==============================] - 1s 865us/step - loss: 0.4064 - accuracy: 0.8095 - val_loss: 0.4092 - val_accuracy: 0.8186\n",
      "Epoch 105/500\n",
      "918/918 [==============================] - 1s 849us/step - loss: 0.4061 - accuracy: 0.8092 - val_loss: 0.4090 - val_accuracy: 0.8175\n",
      "Epoch 106/500\n",
      "918/918 [==============================] - 1s 833us/step - loss: 0.4061 - accuracy: 0.8086 - val_loss: 0.4091 - val_accuracy: 0.8186\n",
      "Epoch 107/500\n",
      "918/918 [==============================] - 1s 821us/step - loss: 0.4060 - accuracy: 0.8084 - val_loss: 0.4090 - val_accuracy: 0.8181\n",
      "Epoch 108/500\n",
      "918/918 [==============================] - 1s 837us/step - loss: 0.4059 - accuracy: 0.8096 - val_loss: 0.4093 - val_accuracy: 0.8181\n",
      "Epoch 109/500\n",
      "918/918 [==============================] - 1s 855us/step - loss: 0.4058 - accuracy: 0.8100 - val_loss: 0.4091 - val_accuracy: 0.8192\n",
      "Epoch 110/500\n",
      "918/918 [==============================] - 1s 818us/step - loss: 0.4056 - accuracy: 0.8089 - val_loss: 0.4087 - val_accuracy: 0.8192\n",
      "Epoch 111/500\n",
      "918/918 [==============================] - 1s 844us/step - loss: 0.4055 - accuracy: 0.8101 - val_loss: 0.4087 - val_accuracy: 0.8214\n",
      "Epoch 112/500\n",
      "918/918 [==============================] - 1s 834us/step - loss: 0.4053 - accuracy: 0.8096 - val_loss: 0.4088 - val_accuracy: 0.8175\n",
      "Epoch 113/500\n",
      "918/918 [==============================] - 1s 849us/step - loss: 0.4052 - accuracy: 0.8105 - val_loss: 0.4085 - val_accuracy: 0.8181\n",
      "Epoch 114/500\n",
      "918/918 [==============================] - 1s 821us/step - loss: 0.4052 - accuracy: 0.8107 - val_loss: 0.4089 - val_accuracy: 0.8186\n",
      "Epoch 115/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.4052 - accuracy: 0.8093 - val_loss: 0.4090 - val_accuracy: 0.8192\n",
      "Epoch 116/500\n",
      "918/918 [==============================] - 1s 821us/step - loss: 0.4048 - accuracy: 0.8104 - val_loss: 0.4088 - val_accuracy: 0.8192\n",
      "Epoch 117/500\n",
      "918/918 [==============================] - 1s 821us/step - loss: 0.4047 - accuracy: 0.8114 - val_loss: 0.4086 - val_accuracy: 0.8203\n",
      "Epoch 118/500\n",
      "918/918 [==============================] - 1s 821us/step - loss: 0.4047 - accuracy: 0.8103 - val_loss: 0.4086 - val_accuracy: 0.8197\n",
      "Epoch 119/500\n",
      "918/918 [==============================] - 1s 871us/step - loss: 0.4045 - accuracy: 0.8112 - val_loss: 0.4086 - val_accuracy: 0.8219\n",
      "Epoch 120/500\n",
      "918/918 [==============================] - 1s 815us/step - loss: 0.4044 - accuracy: 0.8120 - val_loss: 0.4081 - val_accuracy: 0.8197\n",
      "Epoch 121/500\n",
      "918/918 [==============================] - 1s 816us/step - loss: 0.4042 - accuracy: 0.8110 - val_loss: 0.4082 - val_accuracy: 0.8203\n",
      "Epoch 122/500\n",
      "918/918 [==============================] - 1s 832us/step - loss: 0.4043 - accuracy: 0.8107 - val_loss: 0.4080 - val_accuracy: 0.8192\n",
      "Epoch 123/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.4040 - accuracy: 0.8115 - val_loss: 0.4084 - val_accuracy: 0.8192\n",
      "Epoch 124/500\n",
      "918/918 [==============================] - 1s 853us/step - loss: 0.4040 - accuracy: 0.8114 - val_loss: 0.4082 - val_accuracy: 0.8170\n",
      "Epoch 125/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.4038 - accuracy: 0.8105 - val_loss: 0.4079 - val_accuracy: 0.8181\n",
      "Epoch 126/500\n",
      "918/918 [==============================] - 1s 829us/step - loss: 0.4038 - accuracy: 0.8111 - val_loss: 0.4081 - val_accuracy: 0.8181\n",
      "Epoch 127/500\n",
      "918/918 [==============================] - 1s 825us/step - loss: 0.4036 - accuracy: 0.8114 - val_loss: 0.4079 - val_accuracy: 0.8192\n",
      "Epoch 128/500\n",
      "918/918 [==============================] - 1s 816us/step - loss: 0.4033 - accuracy: 0.8107 - val_loss: 0.4084 - val_accuracy: 0.8224\n",
      "Epoch 129/500\n",
      "918/918 [==============================] - 1s 860us/step - loss: 0.4033 - accuracy: 0.8124 - val_loss: 0.4077 - val_accuracy: 0.8197\n",
      "Epoch 130/500\n",
      "918/918 [==============================] - 1s 841us/step - loss: 0.4033 - accuracy: 0.8114 - val_loss: 0.4078 - val_accuracy: 0.8203\n",
      "Epoch 131/500\n",
      "918/918 [==============================] - 1s 814us/step - loss: 0.4031 - accuracy: 0.8119 - val_loss: 0.4081 - val_accuracy: 0.8175\n",
      "Epoch 132/500\n",
      "918/918 [==============================] - 1s 826us/step - loss: 0.4030 - accuracy: 0.8119 - val_loss: 0.4077 - val_accuracy: 0.8203\n",
      "Epoch 133/500\n",
      "918/918 [==============================] - 1s 825us/step - loss: 0.4030 - accuracy: 0.8115 - val_loss: 0.4079 - val_accuracy: 0.8170\n",
      "Epoch 134/500\n",
      "918/918 [==============================] - 1s 853us/step - loss: 0.4029 - accuracy: 0.8127 - val_loss: 0.4076 - val_accuracy: 0.8192\n",
      "Epoch 135/500\n",
      "918/918 [==============================] - 1s 828us/step - loss: 0.4027 - accuracy: 0.8123 - val_loss: 0.4077 - val_accuracy: 0.8192\n",
      "Epoch 136/500\n",
      "918/918 [==============================] - 1s 811us/step - loss: 0.4026 - accuracy: 0.8133 - val_loss: 0.4080 - val_accuracy: 0.8197\n",
      "Epoch 137/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.4024 - accuracy: 0.8124 - val_loss: 0.4077 - val_accuracy: 0.8192\n",
      "Epoch 138/500\n",
      "918/918 [==============================] - 1s 818us/step - loss: 0.4024 - accuracy: 0.8127 - val_loss: 0.4082 - val_accuracy: 0.8175\n",
      "Epoch 139/500\n",
      "918/918 [==============================] - 1s 878us/step - loss: 0.4021 - accuracy: 0.8131 - val_loss: 0.4085 - val_accuracy: 0.8170\n",
      "Epoch 140/500\n",
      "918/918 [==============================] - 1s 828us/step - loss: 0.4022 - accuracy: 0.8118 - val_loss: 0.4075 - val_accuracy: 0.8186\n",
      "Epoch 141/500\n",
      "918/918 [==============================] - 1s 813us/step - loss: 0.4020 - accuracy: 0.8124 - val_loss: 0.4081 - val_accuracy: 0.8159\n",
      "Epoch 142/500\n",
      "918/918 [==============================] - 1s 814us/step - loss: 0.4020 - accuracy: 0.8122 - val_loss: 0.4079 - val_accuracy: 0.8159\n",
      "Epoch 143/500\n",
      "918/918 [==============================] - 1s 820us/step - loss: 0.4017 - accuracy: 0.8114 - val_loss: 0.4081 - val_accuracy: 0.8175\n",
      "Epoch 144/500\n",
      "918/918 [==============================] - 1s 869us/step - loss: 0.4016 - accuracy: 0.8119 - val_loss: 0.4076 - val_accuracy: 0.8170\n",
      "Epoch 145/500\n",
      "918/918 [==============================] - 1s 814us/step - loss: 0.4015 - accuracy: 0.8123 - val_loss: 0.4081 - val_accuracy: 0.8170\n",
      "Epoch 146/500\n",
      "918/918 [==============================] - 1s 818us/step - loss: 0.4015 - accuracy: 0.8118 - val_loss: 0.4075 - val_accuracy: 0.8170\n",
      "Epoch 147/500\n",
      "918/918 [==============================] - 1s 817us/step - loss: 0.4015 - accuracy: 0.8119 - val_loss: 0.4076 - val_accuracy: 0.8175\n",
      "Epoch 148/500\n",
      "918/918 [==============================] - 1s 866us/step - loss: 0.4015 - accuracy: 0.8127 - val_loss: 0.4078 - val_accuracy: 0.8164\n",
      "Epoch 149/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.4012 - accuracy: 0.8123 - val_loss: 0.4080 - val_accuracy: 0.8175\n",
      "Epoch 150/500\n",
      "918/918 [==============================] - 1s 812us/step - loss: 0.4013 - accuracy: 0.8129 - val_loss: 0.4076 - val_accuracy: 0.8164\n",
      "Epoch 151/500\n",
      "918/918 [==============================] - 1s 827us/step - loss: 0.4010 - accuracy: 0.8120 - val_loss: 0.4077 - val_accuracy: 0.8170\n",
      "Epoch 152/500\n",
      "918/918 [==============================] - 1s 814us/step - loss: 0.4011 - accuracy: 0.8119 - val_loss: 0.4076 - val_accuracy: 0.8170\n",
      "Epoch 153/500\n",
      "918/918 [==============================] - 1s 859us/step - loss: 0.4009 - accuracy: 0.8118 - val_loss: 0.4075 - val_accuracy: 0.8175\n",
      "Epoch 154/500\n",
      "918/918 [==============================] - 1s 826us/step - loss: 0.4009 - accuracy: 0.8120 - val_loss: 0.4075 - val_accuracy: 0.8170\n",
      "Epoch 155/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.4007 - accuracy: 0.8127 - val_loss: 0.4073 - val_accuracy: 0.8175\n",
      "Epoch 156/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.4006 - accuracy: 0.8123 - val_loss: 0.4080 - val_accuracy: 0.8197\n",
      "Epoch 157/500\n",
      "918/918 [==============================] - 1s 811us/step - loss: 0.4005 - accuracy: 0.8123 - val_loss: 0.4078 - val_accuracy: 0.8164\n",
      "Epoch 158/500\n",
      "918/918 [==============================] - 1s 865us/step - loss: 0.4003 - accuracy: 0.8112 - val_loss: 0.4072 - val_accuracy: 0.8186\n",
      "Epoch 159/500\n",
      "918/918 [==============================] - 1s 821us/step - loss: 0.4004 - accuracy: 0.8116 - val_loss: 0.4076 - val_accuracy: 0.8181\n",
      "Epoch 160/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.4003 - accuracy: 0.8107 - val_loss: 0.4072 - val_accuracy: 0.8186\n",
      "Epoch 161/500\n",
      "918/918 [==============================] - 1s 815us/step - loss: 0.4001 - accuracy: 0.8122 - val_loss: 0.4072 - val_accuracy: 0.8192\n",
      "Epoch 162/500\n",
      "918/918 [==============================] - 1s 834us/step - loss: 0.4001 - accuracy: 0.8116 - val_loss: 0.4070 - val_accuracy: 0.8192\n",
      "Epoch 163/500\n",
      "918/918 [==============================] - 1s 859us/step - loss: 0.3998 - accuracy: 0.8124 - val_loss: 0.4075 - val_accuracy: 0.8170\n",
      "Epoch 164/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.3998 - accuracy: 0.8118 - val_loss: 0.4072 - val_accuracy: 0.8197\n",
      "Epoch 165/500\n",
      "918/918 [==============================] - 1s 826us/step - loss: 0.3999 - accuracy: 0.8130 - val_loss: 0.4070 - val_accuracy: 0.8192\n",
      "Epoch 166/500\n",
      "918/918 [==============================] - 1s 815us/step - loss: 0.3998 - accuracy: 0.8120 - val_loss: 0.4072 - val_accuracy: 0.8181\n",
      "Epoch 167/500\n",
      "918/918 [==============================] - 1s 867us/step - loss: 0.3995 - accuracy: 0.8134 - val_loss: 0.4068 - val_accuracy: 0.8186\n",
      "Epoch 168/500\n",
      "918/918 [==============================] - 1s 815us/step - loss: 0.3997 - accuracy: 0.8129 - val_loss: 0.4070 - val_accuracy: 0.8192\n",
      "Epoch 169/500\n",
      "918/918 [==============================] - 1s 820us/step - loss: 0.3996 - accuracy: 0.8127 - val_loss: 0.4069 - val_accuracy: 0.8203\n",
      "Epoch 170/500\n",
      "918/918 [==============================] - 1s 823us/step - loss: 0.3995 - accuracy: 0.8123 - val_loss: 0.4068 - val_accuracy: 0.8208\n",
      "Epoch 171/500\n",
      "918/918 [==============================] - 1s 814us/step - loss: 0.3994 - accuracy: 0.8126 - val_loss: 0.4071 - val_accuracy: 0.8197\n",
      "Epoch 172/500\n",
      "918/918 [==============================] - 1s 871us/step - loss: 0.3993 - accuracy: 0.8123 - val_loss: 0.4072 - val_accuracy: 0.8214\n",
      "Epoch 173/500\n",
      "918/918 [==============================] - 1s 816us/step - loss: 0.3993 - accuracy: 0.8130 - val_loss: 0.4070 - val_accuracy: 0.8192\n",
      "Epoch 174/500\n",
      "918/918 [==============================] - 1s 812us/step - loss: 0.3991 - accuracy: 0.8134 - val_loss: 0.4070 - val_accuracy: 0.8186\n",
      "Epoch 175/500\n",
      "918/918 [==============================] - 1s 816us/step - loss: 0.3992 - accuracy: 0.8126 - val_loss: 0.4069 - val_accuracy: 0.8197\n",
      "Epoch 176/500\n",
      "918/918 [==============================] - 1s 868us/step - loss: 0.3989 - accuracy: 0.8133 - val_loss: 0.4069 - val_accuracy: 0.8170\n",
      "Epoch 177/500\n",
      "918/918 [==============================] - 1s 813us/step - loss: 0.3990 - accuracy: 0.8134 - val_loss: 0.4071 - val_accuracy: 0.8192\n",
      "Epoch 178/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.3990 - accuracy: 0.8126 - val_loss: 0.4067 - val_accuracy: 0.8197\n",
      "Epoch 179/500\n",
      "918/918 [==============================] - 1s 833us/step - loss: 0.3988 - accuracy: 0.8139 - val_loss: 0.4071 - val_accuracy: 0.8203\n",
      "Epoch 180/500\n",
      "918/918 [==============================] - 1s 825us/step - loss: 0.3989 - accuracy: 0.8126 - val_loss: 0.4070 - val_accuracy: 0.8203\n",
      "Epoch 181/500\n",
      "918/918 [==============================] - 1s 865us/step - loss: 0.3986 - accuracy: 0.8130 - val_loss: 0.4066 - val_accuracy: 0.8197\n",
      "Epoch 182/500\n",
      "918/918 [==============================] - 1s 813us/step - loss: 0.3985 - accuracy: 0.8127 - val_loss: 0.4064 - val_accuracy: 0.8208\n",
      "Epoch 183/500\n",
      "918/918 [==============================] - 1s 829us/step - loss: 0.3983 - accuracy: 0.8141 - val_loss: 0.4068 - val_accuracy: 0.8186\n",
      "Epoch 184/500\n",
      "918/918 [==============================] - 1s 816us/step - loss: 0.3984 - accuracy: 0.8131 - val_loss: 0.4063 - val_accuracy: 0.8219\n",
      "Epoch 185/500\n",
      "918/918 [==============================] - 1s 877us/step - loss: 0.3983 - accuracy: 0.8146 - val_loss: 0.4065 - val_accuracy: 0.8203\n",
      "Epoch 186/500\n",
      "918/918 [==============================] - 1s 826us/step - loss: 0.3983 - accuracy: 0.8141 - val_loss: 0.4068 - val_accuracy: 0.8186\n",
      "Epoch 187/500\n",
      "918/918 [==============================] - 1s 827us/step - loss: 0.3981 - accuracy: 0.8161 - val_loss: 0.4065 - val_accuracy: 0.8203\n",
      "Epoch 188/500\n",
      "918/918 [==============================] - 1s 816us/step - loss: 0.3981 - accuracy: 0.8139 - val_loss: 0.4064 - val_accuracy: 0.8192\n",
      "Epoch 189/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.3977 - accuracy: 0.8131 - val_loss: 0.4068 - val_accuracy: 0.8230\n",
      "Epoch 190/500\n",
      "918/918 [==============================] - 1s 860us/step - loss: 0.3979 - accuracy: 0.8159 - val_loss: 0.4064 - val_accuracy: 0.8208\n",
      "Epoch 191/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.3980 - accuracy: 0.8139 - val_loss: 0.4067 - val_accuracy: 0.8192\n",
      "Epoch 192/500\n",
      "918/918 [==============================] - 1s 813us/step - loss: 0.3977 - accuracy: 0.8153 - val_loss: 0.4066 - val_accuracy: 0.8197\n",
      "Epoch 193/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.3979 - accuracy: 0.8144 - val_loss: 0.4068 - val_accuracy: 0.8186\n",
      "Epoch 194/500\n",
      "918/918 [==============================] - 1s 870us/step - loss: 0.3976 - accuracy: 0.8165 - val_loss: 0.4066 - val_accuracy: 0.8197\n",
      "Epoch 195/500\n",
      "918/918 [==============================] - 1s 817us/step - loss: 0.3976 - accuracy: 0.8148 - val_loss: 0.4066 - val_accuracy: 0.8203\n",
      "Epoch 196/500\n",
      "918/918 [==============================] - 1s 820us/step - loss: 0.3973 - accuracy: 0.8137 - val_loss: 0.4072 - val_accuracy: 0.8208\n",
      "Epoch 197/500\n",
      "918/918 [==============================] - 1s 834us/step - loss: 0.3973 - accuracy: 0.8144 - val_loss: 0.4068 - val_accuracy: 0.8197\n",
      "Epoch 198/500\n",
      "918/918 [==============================] - 1s 856us/step - loss: 0.3975 - accuracy: 0.8149 - val_loss: 0.4065 - val_accuracy: 0.8197\n",
      "Epoch 199/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.3973 - accuracy: 0.8144 - val_loss: 0.4065 - val_accuracy: 0.8197\n",
      "Epoch 200/500\n",
      "918/918 [==============================] - 1s 813us/step - loss: 0.3971 - accuracy: 0.8142 - val_loss: 0.4067 - val_accuracy: 0.8181\n",
      "Epoch 201/500\n",
      "918/918 [==============================] - 1s 834us/step - loss: 0.3971 - accuracy: 0.8153 - val_loss: 0.4068 - val_accuracy: 0.8186\n",
      "Epoch 202/500\n",
      "918/918 [==============================] - 1s 820us/step - loss: 0.3972 - accuracy: 0.8139 - val_loss: 0.4064 - val_accuracy: 0.8197\n",
      "Epoch 203/500\n",
      "918/918 [==============================] - 1s 851us/step - loss: 0.3971 - accuracy: 0.8152 - val_loss: 0.4066 - val_accuracy: 0.8214\n",
      "Epoch 204/500\n",
      "918/918 [==============================] - 1s 836us/step - loss: 0.3970 - accuracy: 0.8159 - val_loss: 0.4063 - val_accuracy: 0.8192\n",
      "Epoch 205/500\n",
      "918/918 [==============================] - 1s 817us/step - loss: 0.3968 - accuracy: 0.8160 - val_loss: 0.4062 - val_accuracy: 0.8230\n",
      "Epoch 206/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.3967 - accuracy: 0.8144 - val_loss: 0.4064 - val_accuracy: 0.8219\n",
      "Epoch 207/500\n",
      "918/918 [==============================] - 1s 856us/step - loss: 0.3968 - accuracy: 0.8169 - val_loss: 0.4066 - val_accuracy: 0.8214\n",
      "Epoch 208/500\n",
      "918/918 [==============================] - 1s 833us/step - loss: 0.3966 - accuracy: 0.8165 - val_loss: 0.4067 - val_accuracy: 0.8181\n",
      "Epoch 209/500\n",
      "918/918 [==============================] - 1s 817us/step - loss: 0.3967 - accuracy: 0.8164 - val_loss: 0.4061 - val_accuracy: 0.8181\n",
      "Epoch 210/500\n",
      "918/918 [==============================] - 1s 823us/step - loss: 0.3965 - accuracy: 0.8150 - val_loss: 0.4060 - val_accuracy: 0.8186\n",
      "Epoch 211/500\n",
      "918/918 [==============================] - 1s 853us/step - loss: 0.3965 - accuracy: 0.8150 - val_loss: 0.4061 - val_accuracy: 0.8186\n",
      "Epoch 212/500\n",
      "918/918 [==============================] - 1s 844us/step - loss: 0.3963 - accuracy: 0.8156 - val_loss: 0.4064 - val_accuracy: 0.8203\n",
      "Epoch 213/500\n",
      "918/918 [==============================] - 1s 821us/step - loss: 0.3964 - accuracy: 0.8165 - val_loss: 0.4063 - val_accuracy: 0.8175\n",
      "Epoch 214/500\n",
      "918/918 [==============================] - 1s 823us/step - loss: 0.3963 - accuracy: 0.8164 - val_loss: 0.4067 - val_accuracy: 0.8192\n",
      "Epoch 215/500\n",
      "918/918 [==============================] - 1s 835us/step - loss: 0.3963 - accuracy: 0.8163 - val_loss: 0.4060 - val_accuracy: 0.8214\n",
      "Epoch 216/500\n",
      "918/918 [==============================] - 1s 868us/step - loss: 0.3962 - accuracy: 0.8161 - val_loss: 0.4064 - val_accuracy: 0.8197\n",
      "Epoch 217/500\n",
      "918/918 [==============================] - 1s 823us/step - loss: 0.3961 - accuracy: 0.8167 - val_loss: 0.4066 - val_accuracy: 0.8197\n",
      "Epoch 218/500\n",
      "918/918 [==============================] - 1s 845us/step - loss: 0.3961 - accuracy: 0.8156 - val_loss: 0.4063 - val_accuracy: 0.8203\n",
      "Epoch 219/500\n",
      "918/918 [==============================] - 1s 893us/step - loss: 0.3961 - accuracy: 0.8167 - val_loss: 0.4060 - val_accuracy: 0.8214\n",
      "Epoch 220/500\n",
      "918/918 [==============================] - 1s 871us/step - loss: 0.3958 - accuracy: 0.8149 - val_loss: 0.4058 - val_accuracy: 0.8214\n",
      "Epoch 221/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.3957 - accuracy: 0.8160 - val_loss: 0.4060 - val_accuracy: 0.8192\n",
      "Epoch 222/500\n",
      "918/918 [==============================] - 1s 840us/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.4062 - val_accuracy: 0.8224\n",
      "Epoch 223/500\n",
      "918/918 [==============================] - 1s 833us/step - loss: 0.3956 - accuracy: 0.8169 - val_loss: 0.4058 - val_accuracy: 0.8197\n",
      "Epoch 224/500\n",
      "918/918 [==============================] - 1s 858us/step - loss: 0.3957 - accuracy: 0.8156 - val_loss: 0.4059 - val_accuracy: 0.8219\n",
      "Epoch 225/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.3955 - accuracy: 0.8172 - val_loss: 0.4059 - val_accuracy: 0.8208\n",
      "Epoch 226/500\n",
      "918/918 [==============================] - 1s 844us/step - loss: 0.3955 - accuracy: 0.8156 - val_loss: 0.4058 - val_accuracy: 0.8203\n",
      "Epoch 227/500\n",
      "918/918 [==============================] - 1s 823us/step - loss: 0.3955 - accuracy: 0.8157 - val_loss: 0.4061 - val_accuracy: 0.8208\n",
      "Epoch 228/500\n",
      "918/918 [==============================] - 1s 872us/step - loss: 0.3953 - accuracy: 0.8156 - val_loss: 0.4062 - val_accuracy: 0.8197\n",
      "Epoch 229/500\n",
      "918/918 [==============================] - 1s 842us/step - loss: 0.3952 - accuracy: 0.8168 - val_loss: 0.4057 - val_accuracy: 0.8224\n",
      "Epoch 230/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.3952 - accuracy: 0.8154 - val_loss: 0.4058 - val_accuracy: 0.8224\n",
      "Epoch 231/500\n",
      "918/918 [==============================] - 1s 829us/step - loss: 0.3951 - accuracy: 0.8169 - val_loss: 0.4056 - val_accuracy: 0.8208\n",
      "Epoch 232/500\n",
      "918/918 [==============================] - 1s 858us/step - loss: 0.3951 - accuracy: 0.8165 - val_loss: 0.4057 - val_accuracy: 0.8208\n",
      "Epoch 233/500\n",
      "918/918 [==============================] - 1s 844us/step - loss: 0.3946 - accuracy: 0.8168 - val_loss: 0.4064 - val_accuracy: 0.8208\n",
      "Epoch 234/500\n",
      "918/918 [==============================] - 1s 823us/step - loss: 0.3950 - accuracy: 0.8171 - val_loss: 0.4060 - val_accuracy: 0.8214\n",
      "Epoch 235/500\n",
      "918/918 [==============================] - 1s 826us/step - loss: 0.3948 - accuracy: 0.8149 - val_loss: 0.4063 - val_accuracy: 0.8186\n",
      "Epoch 236/500\n",
      "918/918 [==============================] - 1s 886us/step - loss: 0.3948 - accuracy: 0.8169 - val_loss: 0.4060 - val_accuracy: 0.8203\n",
      "Epoch 237/500\n",
      "918/918 [==============================] - 1s 823us/step - loss: 0.3947 - accuracy: 0.8174 - val_loss: 0.4059 - val_accuracy: 0.8197\n",
      "Epoch 238/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.3948 - accuracy: 0.8174 - val_loss: 0.4060 - val_accuracy: 0.8197\n",
      "Epoch 239/500\n",
      "918/918 [==============================] - 1s 842us/step - loss: 0.3946 - accuracy: 0.8169 - val_loss: 0.4058 - val_accuracy: 0.8203\n",
      "Epoch 240/500\n",
      "918/918 [==============================] - 1s 870us/step - loss: 0.3944 - accuracy: 0.8169 - val_loss: 0.4059 - val_accuracy: 0.8203\n",
      "Epoch 241/500\n",
      "918/918 [==============================] - 1s 826us/step - loss: 0.3945 - accuracy: 0.8175 - val_loss: 0.4055 - val_accuracy: 0.8214\n",
      "Epoch 242/500\n",
      "918/918 [==============================] - 1s 830us/step - loss: 0.3944 - accuracy: 0.8167 - val_loss: 0.4055 - val_accuracy: 0.8197\n",
      "Epoch 243/500\n",
      "918/918 [==============================] - 1s 840us/step - loss: 0.3943 - accuracy: 0.8160 - val_loss: 0.4053 - val_accuracy: 0.8203\n",
      "Epoch 244/500\n",
      "918/918 [==============================] - 1s 867us/step - loss: 0.3942 - accuracy: 0.8179 - val_loss: 0.4058 - val_accuracy: 0.8230\n",
      "Epoch 245/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.3940 - accuracy: 0.8174 - val_loss: 0.4055 - val_accuracy: 0.8214\n",
      "Epoch 246/500\n",
      "918/918 [==============================] - 1s 831us/step - loss: 0.3941 - accuracy: 0.8167 - val_loss: 0.4054 - val_accuracy: 0.8214\n",
      "Epoch 247/500\n",
      "918/918 [==============================] - 1s 835us/step - loss: 0.3941 - accuracy: 0.8168 - val_loss: 0.4054 - val_accuracy: 0.8203\n",
      "Epoch 248/500\n",
      "918/918 [==============================] - 1s 864us/step - loss: 0.3941 - accuracy: 0.8176 - val_loss: 0.4052 - val_accuracy: 0.8214\n",
      "Epoch 249/500\n",
      "918/918 [==============================] - 1s 836us/step - loss: 0.3939 - accuracy: 0.8191 - val_loss: 0.4054 - val_accuracy: 0.8197\n",
      "Epoch 250/500\n",
      "918/918 [==============================] - 1s 835us/step - loss: 0.3938 - accuracy: 0.8184 - val_loss: 0.4054 - val_accuracy: 0.8214\n",
      "Epoch 251/500\n",
      "918/918 [==============================] - 1s 818us/step - loss: 0.3937 - accuracy: 0.8149 - val_loss: 0.4053 - val_accuracy: 0.8214\n",
      "Epoch 252/500\n",
      "918/918 [==============================] - 1s 879us/step - loss: 0.3937 - accuracy: 0.8171 - val_loss: 0.4050 - val_accuracy: 0.8208\n",
      "Epoch 253/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.3937 - accuracy: 0.8168 - val_loss: 0.4047 - val_accuracy: 0.8219\n",
      "Epoch 254/500\n",
      "918/918 [==============================] - 1s 825us/step - loss: 0.3936 - accuracy: 0.8171 - val_loss: 0.4052 - val_accuracy: 0.8230\n",
      "Epoch 255/500\n",
      "918/918 [==============================] - 1s 837us/step - loss: 0.3935 - accuracy: 0.8175 - val_loss: 0.4050 - val_accuracy: 0.8214\n",
      "Epoch 256/500\n",
      "918/918 [==============================] - 1s 861us/step - loss: 0.3935 - accuracy: 0.8172 - val_loss: 0.4050 - val_accuracy: 0.8224\n",
      "Epoch 257/500\n",
      "918/918 [==============================] - 1s 839us/step - loss: 0.3935 - accuracy: 0.8176 - val_loss: 0.4048 - val_accuracy: 0.8235\n",
      "Epoch 258/500\n",
      "918/918 [==============================] - 1s 834us/step - loss: 0.3932 - accuracy: 0.8174 - val_loss: 0.4049 - val_accuracy: 0.8241\n",
      "Epoch 259/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.3933 - accuracy: 0.8198 - val_loss: 0.4051 - val_accuracy: 0.8214\n",
      "Epoch 260/500\n",
      "918/918 [==============================] - 1s 862us/step - loss: 0.3932 - accuracy: 0.8164 - val_loss: 0.4052 - val_accuracy: 0.8230\n",
      "Epoch 261/500\n",
      "918/918 [==============================] - 1s 841us/step - loss: 0.3931 - accuracy: 0.8180 - val_loss: 0.4051 - val_accuracy: 0.8235\n",
      "Epoch 262/500\n",
      "918/918 [==============================] - 1s 819us/step - loss: 0.3931 - accuracy: 0.8174 - val_loss: 0.4051 - val_accuracy: 0.8230\n",
      "Epoch 263/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.3931 - accuracy: 0.8174 - val_loss: 0.4045 - val_accuracy: 0.8230\n",
      "Epoch 264/500\n",
      "918/918 [==============================] - 1s 879us/step - loss: 0.3931 - accuracy: 0.8179 - val_loss: 0.4048 - val_accuracy: 0.8246\n",
      "Epoch 265/500\n",
      "918/918 [==============================] - 1s 823us/step - loss: 0.3929 - accuracy: 0.8178 - val_loss: 0.4048 - val_accuracy: 0.8214\n",
      "Epoch 266/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.3929 - accuracy: 0.8171 - val_loss: 0.4051 - val_accuracy: 0.8219\n",
      "Epoch 267/500\n",
      "918/918 [==============================] - 1s 863us/step - loss: 0.3928 - accuracy: 0.8187 - val_loss: 0.4055 - val_accuracy: 0.8214\n",
      "Epoch 268/500\n",
      "918/918 [==============================] - 1s 831us/step - loss: 0.3926 - accuracy: 0.8172 - val_loss: 0.4052 - val_accuracy: 0.8208\n",
      "Epoch 269/500\n",
      "918/918 [==============================] - 1s 820us/step - loss: 0.3928 - accuracy: 0.8178 - val_loss: 0.4047 - val_accuracy: 0.8230\n",
      "Epoch 270/500\n",
      "918/918 [==============================] - 1s 833us/step - loss: 0.3928 - accuracy: 0.8174 - val_loss: 0.4050 - val_accuracy: 0.8224\n",
      "Epoch 271/500\n",
      "918/918 [==============================] - 1s 860us/step - loss: 0.3927 - accuracy: 0.8182 - val_loss: 0.4052 - val_accuracy: 0.8214\n",
      "Epoch 272/500\n",
      "918/918 [==============================] - 1s 821us/step - loss: 0.3927 - accuracy: 0.8164 - val_loss: 0.4045 - val_accuracy: 0.8235\n",
      "Epoch 273/500\n",
      "918/918 [==============================] - 1s 829us/step - loss: 0.3926 - accuracy: 0.8183 - val_loss: 0.4045 - val_accuracy: 0.8230\n",
      "Epoch 274/500\n",
      "918/918 [==============================] - 1s 820us/step - loss: 0.3925 - accuracy: 0.8171 - val_loss: 0.4048 - val_accuracy: 0.8208\n",
      "Epoch 275/500\n",
      "918/918 [==============================] - 1s 871us/step - loss: 0.3924 - accuracy: 0.8190 - val_loss: 0.4045 - val_accuracy: 0.8241\n",
      "Epoch 276/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.3926 - accuracy: 0.8180 - val_loss: 0.4045 - val_accuracy: 0.8230\n",
      "Epoch 277/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.3924 - accuracy: 0.8191 - val_loss: 0.4053 - val_accuracy: 0.8203\n",
      "Epoch 278/500\n",
      "918/918 [==============================] - 1s 832us/step - loss: 0.3923 - accuracy: 0.8178 - val_loss: 0.4049 - val_accuracy: 0.8214\n",
      "Epoch 279/500\n",
      "918/918 [==============================] - 1s 862us/step - loss: 0.3924 - accuracy: 0.8180 - val_loss: 0.4049 - val_accuracy: 0.8224\n",
      "Epoch 280/500\n",
      "918/918 [==============================] - 1s 820us/step - loss: 0.3922 - accuracy: 0.8176 - val_loss: 0.4046 - val_accuracy: 0.8224\n",
      "Epoch 281/500\n",
      "918/918 [==============================] - 1s 833us/step - loss: 0.3924 - accuracy: 0.8182 - val_loss: 0.4046 - val_accuracy: 0.8241\n",
      "Epoch 282/500\n",
      "918/918 [==============================] - 1s 867us/step - loss: 0.3921 - accuracy: 0.8187 - val_loss: 0.4048 - val_accuracy: 0.8230\n",
      "Epoch 283/500\n",
      "918/918 [==============================] - 1s 824us/step - loss: 0.3921 - accuracy: 0.8179 - val_loss: 0.4051 - val_accuracy: 0.8219\n",
      "Epoch 284/500\n",
      "918/918 [==============================] - 1s 835us/step - loss: 0.3921 - accuracy: 0.8189 - val_loss: 0.4050 - val_accuracy: 0.8246\n",
      "Epoch 285/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.3922 - accuracy: 0.8182 - val_loss: 0.4047 - val_accuracy: 0.8235\n",
      "Epoch 286/500\n",
      "918/918 [==============================] - 1s 869us/step - loss: 0.3921 - accuracy: 0.8191 - val_loss: 0.4046 - val_accuracy: 0.8246\n",
      "Epoch 287/500\n",
      "918/918 [==============================] - 1s 828us/step - loss: 0.3921 - accuracy: 0.8174 - val_loss: 0.4049 - val_accuracy: 0.8208\n",
      "Epoch 288/500\n",
      "918/918 [==============================] - 1s 822us/step - loss: 0.3917 - accuracy: 0.8199 - val_loss: 0.4049 - val_accuracy: 0.8219\n",
      "Epoch 289/500\n",
      "918/918 [==============================] - 1s 841us/step - loss: 0.3920 - accuracy: 0.8165 - val_loss: 0.4046 - val_accuracy: 0.8219\n",
      "Epoch 290/500\n",
      "918/918 [==============================] - 1s 864us/step - loss: 0.3918 - accuracy: 0.8184 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
      "Epoch 291/500\n",
      "918/918 [==============================] - 1s 827us/step - loss: 0.3919 - accuracy: 0.8202 - val_loss: 0.4052 - val_accuracy: 0.8219\n",
      "Epoch 292/500\n",
      "918/918 [==============================] - 1s 837us/step - loss: 0.3918 - accuracy: 0.8189 - val_loss: 0.4047 - val_accuracy: 0.8235\n",
      "Epoch 293/500\n",
      "918/918 [==============================] - 1s 870us/step - loss: 0.3917 - accuracy: 0.8180 - val_loss: 0.4052 - val_accuracy: 0.8219\n",
      "58/58 [==============================] - 0s 516us/step - loss: 0.4045 - accuracy: 0.8230\n",
      "Test Loss: 0.40445807576179504, Test Accuracy: 0.8229847550392151\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Reset model weights\n",
    "model_tnn.set_weights([np.random.permutation(w.flat).reshape(w.shape) for w in model_tnn.get_weights()])\n",
    "\n",
    "# Train Model, set early stopping and patience\n",
    "fitModel = model_tnn.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=500, batch_size=8,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Save History for Plotting\n",
    "history = fitModel.history\n",
    "\n",
    "model_tnn.save(f'{model_dir}/NNmodel.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_tnn.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07b993e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models//nn_history.sav']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save history\n",
    "joblib.dump(history, f'{model_dir}/nn_history.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e23e542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66198d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 891us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "y_pred = (model_tnn.predict(x_test) > 0.5).astype(\"int32\")\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43914445",
   "metadata": {},
   "source": [
    "# 6 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16869953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best parameters: {'colsample_bytree': 0.7, 'eta': 0.1, 'max_depth': 7, 'subsample': 0.8}\n",
      "Best cross-validation accuracy: 0.8430938765365232\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'colsample_bytree': 0.7, 'eta': 0.01, 'max_de...         0.806999   \n",
      "1    {'colsample_bytree': 0.7, 'eta': 0.01, 'max_de...         0.804956   \n",
      "2    {'colsample_bytree': 0.7, 'eta': 0.01, 'max_de...         0.804275   \n",
      "3    {'colsample_bytree': 0.7, 'eta': 0.01, 'max_de...         0.820891   \n",
      "4    {'colsample_bytree': 0.7, 'eta': 0.01, 'max_de...         0.820074   \n",
      "..                                                 ...              ...   \n",
      "211  {'colsample_bytree': 1.0, 'eta': 0.3, 'max_dep...         0.833558   \n",
      "212  {'colsample_bytree': 1.0, 'eta': 0.3, 'max_dep...         0.835873   \n",
      "213  {'colsample_bytree': 1.0, 'eta': 0.3, 'max_dep...         0.828247   \n",
      "214  {'colsample_bytree': 1.0, 'eta': 0.3, 'max_dep...         0.830018   \n",
      "215  {'colsample_bytree': 1.0, 'eta': 0.3, 'max_dep...         0.832060   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.006619  \n",
      "1          0.008106  \n",
      "2          0.006098  \n",
      "3          0.009827  \n",
      "4          0.010338  \n",
      "..              ...  \n",
      "211        0.008854  \n",
      "212        0.011894  \n",
      "213        0.008015  \n",
      "214        0.007363  \n",
      "215        0.007136  \n",
      "\n",
      "[216 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models//best_model_xgb.sav']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': np.linspace(3, 10, 8, dtype=int),  # Depth of each tree\n",
    "    'eta': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "base_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'error'\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(**base_params),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "best_model_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_pred_xgb = best_model_xgb.predict(X_test)\n",
    "\n",
    "results_df_xgb = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results_df_xgb[['params', 'mean_test_score', 'std_test_score']])\n",
    "results_df_xgb.to_csv(f'{model_dir}/grid_search_results_xgb.csv', index=False)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_model_xgb, f'{model_dir}/best_model_xgb.sav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6c973",
   "metadata": {},
   "source": [
    "# 6 Get the best-performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598bcbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance on Test Set:\n",
      "Logistic Regression - Test Accuracy: 0.7854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.830     0.715     0.768       913\n",
      "           1      0.752     0.855     0.800       923\n",
      "\n",
      "    accuracy                          0.785      1836\n",
      "   macro avg      0.791     0.785     0.784      1836\n",
      "weighted avg      0.791     0.785     0.784      1836\n",
      "\n",
      "Confusion Matrix components:\n",
      "TN: 653, FP: 260, FN: 134, TP: 789\n",
      "K-Nearest Neighbors - Test Accuracy: 0.7870\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.834     0.714     0.769       913\n",
      "           1      0.752     0.859     0.802       923\n",
      "\n",
      "    accuracy                          0.787      1836\n",
      "   macro avg      0.793     0.787     0.786      1836\n",
      "weighted avg      0.793     0.787     0.786      1836\n",
      "\n",
      "Confusion Matrix components:\n",
      "TN: 652, FP: 261, FN: 130, TP: 793\n",
      "Decision Tree - Test Accuracy: 0.8072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.820     0.784     0.802       913\n",
      "           1      0.795     0.830     0.812       923\n",
      "\n",
      "    accuracy                          0.807      1836\n",
      "   macro avg      0.808     0.807     0.807      1836\n",
      "weighted avg      0.808     0.807     0.807      1836\n",
      "\n",
      "Confusion Matrix components:\n",
      "TN: 716, FP: 197, FN: 157, TP: 766\n",
      "Random Forest - Test Accuracy: 0.8426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.857     0.820     0.838       913\n",
      "           1      0.830     0.865     0.847       923\n",
      "\n",
      "    accuracy                          0.843      1836\n",
      "   macro avg      0.843     0.842     0.842      1836\n",
      "weighted avg      0.843     0.843     0.843      1836\n",
      "\n",
      "Confusion Matrix components:\n",
      "TN: 749, FP: 164, FN: 125, TP: 798\n",
      "58/58 [==============================] - 0s 528us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 15:00:54.657060: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Neural Network - Test Accuracy: 0.8230\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.843     0.792     0.816       913\n",
      "           1      0.806     0.854     0.829       923\n",
      "\n",
      "    accuracy                          0.823      1836\n",
      "   macro avg      0.824     0.823     0.823      1836\n",
      "weighted avg      0.824     0.823     0.823      1836\n",
      "\n",
      "Confusion Matrix components:\n",
      "TN: 723, FP: 190, FN: 135, TP: 788\n",
      "\n",
      "Best Model: Random Forest - Test Accuracy: 0.8426\n",
      "Best model saved as 'best_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "best_model_lr = joblib.load(f'{model_dir}/best_model_lr.sav')\n",
    "best_model_knc = joblib.load(f'{model_dir}/best_model_knc.sav')\n",
    "best_model_dtc = joblib.load(f'{model_dir}/best_model_dtc.sav')\n",
    "best_model_rf = joblib.load(f'{model_dir}/best_model_rf.sav')\n",
    "best_model_tnn = tf.keras.models.load_model(f'{model_dir}/NNmodel.h5')\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': best_model_lr,\n",
    "    'K-Nearest Neighbors': best_model_knc,\n",
    "    'Decision Tree': best_model_dtc,\n",
    "    'Random Forest': best_model_rf,\n",
    "    'Transformer Neural Network': best_model_tnn\n",
    "}\n",
    "\n",
    "# Compare models, and save the best model\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"\\nModel Performance on Test Set:\")\n",
    "best_model_name = None\n",
    "best_model_score = 0.0\n",
    "best_model = None\n",
    "from sklearn.metrics import accuracy_score  \n",
    "for name, model in models.items():\n",
    "    if name == 'Transformer Neural Network':\n",
    "        y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    # print precision, recall, accuracy, and F1-score to the third decimal place, as well as the confusion matrix components (TN, FP, FN, TP)\n",
    "    print(f\"{name} - Test Accuracy: {score:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(f\"Confusion Matrix components:\")\n",
    "    print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
    "\n",
    "    if score > best_model_score:\n",
    "        best_model_score = score\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} - Test Accuracy: {best_model_score:.4f}\")\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "print(f\"Best model saved as 'best_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2d287",
   "metadata": {},
   "source": [
    "# Train a RF model without [Fe/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90bb315c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_no_ksmet.sav']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_koi_smet = X.drop(columns=['koi_smet'])\n",
    "\n",
    "X_train_no_koi_smet, X_test_no_koi_smet, y_train, y_test = train_test_split(X_no_koi_smet, y, random_state=10, test_size=0.2, stratify=y)\n",
    "scaler_no_koi_smet = StandardScaler()\n",
    "X_train_no_koi_smet = pd.DataFrame(scaler_no_koi_smet.fit_transform(X_train_no_koi_smet), columns=X_no_koi_smet.columns)\n",
    "X_test_no_koi_smet = pd.DataFrame(scaler_no_koi_smet.transform(X_test_no_koi_smet), columns=X_no_koi_smet.columns)\n",
    "joblib.dump(scaler_no_koi_smet, 'scaler_no_ksmet.sav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e2bf459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best CV accuracy: 0.9842004903296104\n",
      "Test Accuracy: 0.8349673202614379\n",
      "Confusion Matrix:\n",
      " [[745 168]\n",
      " [135 788]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.847     0.816     0.831       913\n",
      "           1      0.824     0.854     0.839       923\n",
      "\n",
      "    accuracy                          0.835      1836\n",
      "   macro avg      0.835     0.835     0.835      1836\n",
      "weighted avg      0.835     0.835     0.835      1836\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/best_model_rf_no_koi_smet.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "rf_results_df = pd.read_csv(f'{model_dir}/grid_search_results_rf.csv')\n",
    "params = rf_results_df.loc[rf_results_df['mean_test_score'].idxmax(), 'params']\n",
    "\n",
    "# params = {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "# Convert params from string to dict\n",
    "params_dict = ast.literal_eval(params)\n",
    "# reset model weights\n",
    "rf = RandomForestClassifier(random_state=42, **params_dict)\n",
    "\n",
    "rf.fit(X_train_no_koi_smet, y_train)\n",
    "\n",
    "print(\"Best params:\", params)\n",
    "print(\"Best CV accuracy:\", rf.score(X_train_no_koi_smet, y_train))\n",
    "\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_no_koi_smet)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf, digits=3))\n",
    "\n",
    "# save model\n",
    "joblib.dump(rf, 'models/best_model_rf_no_koi_smet.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
